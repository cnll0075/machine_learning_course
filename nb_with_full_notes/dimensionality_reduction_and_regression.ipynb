{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557b4b10-7a0f-4426-8011-280b0d352798",
   "metadata": {},
   "source": [
    "Previously we have talked about using dimensionality technique for data processing/feature selection. In this notebook we will see an example of such workflow, using the store sales forecast example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1d4c1-af22-4089-8997-ea51773309a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load feature engineered datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c7d7c-70bd-433c-8165-fffe677da5c4",
   "metadata": {},
   "source": [
    "We have created lots of time related features before, let's reload the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484580f0-60d3-4979-b926-56e60a4beb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b573f8d-5ebb-44e7-8f25-b0d4515b109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/store/sales_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea237eb-63be-4086-affa-99ac50e32ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales_log</th>\n",
       "      <th>onpromotion_log</th>\n",
       "      <th>is_wknd</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>...</th>\n",
       "      <th>store_nbr_1</th>\n",
       "      <th>store_nbr_2</th>\n",
       "      <th>store_nbr_3</th>\n",
       "      <th>store_nbr_4</th>\n",
       "      <th>store_nbr_5</th>\n",
       "      <th>store_nbr_6</th>\n",
       "      <th>store_nbr_7</th>\n",
       "      <th>store_nbr_8</th>\n",
       "      <th>store_nbr_9</th>\n",
       "      <th>store_nbr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sales_log  onpromotion_log  is_wknd  is_month_start  \\\n",
       "0  2013-01-01   0.000000              0.0        0               1   \n",
       "1  2013-01-02   1.098612              0.0        0               0   \n",
       "2  2013-01-03   0.000000              0.0        0               0   \n",
       "3  2013-01-04   1.386294              0.0        1               0   \n",
       "4  2013-01-05   1.386294              0.0        1               0   \n",
       "\n",
       "   is_month_end  is_quarter_start  is_quarter_end  is_year_start  is_year_end  \\\n",
       "0             0                 1               0              1            0   \n",
       "1             0                 0               0              0            0   \n",
       "2             0                 0               0              0            0   \n",
       "3             0                 0               0              0            0   \n",
       "4             0                 0               0              0            0   \n",
       "\n",
       "   ...  store_nbr_1  store_nbr_2  store_nbr_3  store_nbr_4  store_nbr_5  \\\n",
       "0  ...            1            0            0            0            0   \n",
       "1  ...            1            0            0            0            0   \n",
       "2  ...            1            0            0            0            0   \n",
       "3  ...            1            0            0            0            0   \n",
       "4  ...            1            0            0            0            0   \n",
       "\n",
       "   store_nbr_6  store_nbr_7  store_nbr_8  store_nbr_9  store_nbr_10  \n",
       "0            0            0            0            0             0  \n",
       "1            0            0            0            0             0  \n",
       "2            0            0            0            0             0  \n",
       "3            0            0            0            0             0  \n",
       "4            0            0            0            0             0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0df4e-2560-420b-b8de-30a21f50aa8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train - valid split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20279c-9b2c-490d-9cd3-37f8027dbc43",
   "metadata": {},
   "source": [
    "For time series related predictions, make sure to split train-valid by their time (avoid data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16f27be-f703-4dbd-a55d-562dee86095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['date'] < '2017-01-01']\n",
    "valid = df[df['date'] >= '2017-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77085842-5268-40c6-8ebe-99f1a31d4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['date'], axis=1)\n",
    "valid = valid.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f727598-ae99-4e2c-8bd8-6c9dbd51290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['sales_log']\n",
    "train_X = train.drop(['sales_log'], axis=1)\n",
    "\n",
    "valid_y = valid['sales_log']\n",
    "valid_X = valid.drop(['sales_log'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cc8e58c-a6e3-4eb6-b9fd-2c8f49671cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43710,), (43710, 55), (6810,), (6810, 55))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, train_X.shape, valid_y.shape, valid_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af380f3-2ded-49fd-85b5-cc3b378802d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Perform dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b773f415-779b-4e8a-aa45-09be3e14a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b339e7e-7bfa-4e52-9666-6ae225e639a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_features = pca.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde3b503-4271-426a-b80f-e37aa92c3d19",
   "metadata": {},
   "source": [
    "The 10 features captures 80% of variance of the original dataset (information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d28b49-7a18-4453-8b5d-dd21f1d2bab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8021001768316256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pca.explained_variance_ratio_).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33847f-b825-4b6d-9fb4-5740ba7072ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641bfc5d-68da-4de9-bcd3-d847f5849819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(new_train_features, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb697e-54cf-4db4-ae42-d2e0d4c182bb",
   "metadata": {},
   "source": [
    "Last time, in notebook 06, we have seen that by throwing all features into linear regression, we are seeing severe overfitting and most of the coefficients have extreme high values. Here we can see using the 10 new features, the coefficients are more well behaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ddb75ee-c9f0-4ba4-ad58-cd02e8d8246e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.44882438e-01, -7.22625311e-02,  1.97460204e-01,  2.40064147e-03,\n",
       "        1.51658211e-03, -2.76771424e-04,  2.69603139e-02,  2.83471510e-02,\n",
       "       -4.12241914e-03, -3.54922333e-03])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b378e0e8-d1f2-4c42-b8ed-4cf1b80eca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = linear_model.predict(new_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5b182e5-62ef-4579-a375-5d91e5d2120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7305760028995053\n"
     ]
    }
   ],
   "source": [
    "train_loss = np.sqrt(mean_squared_error(train_y, train_pred))\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6a59f-0e44-4ac2-beac-6aa6cfb5b51e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Making predictions on valid dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb2068-b6ea-4e95-899f-3dc37fbcb87c",
   "metadata": {},
   "source": [
    "First, we have to also use the PCA model trained on the training dataset to tranform our valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e80accf-f96c-4419-adf2-dfb4c2552e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid_features = pca.transform(valid_X) ## note we're only using transform here, not fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42513f5d-2545-45f8-990d-9deb93420a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.predict(new_valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5c38d3-83da-4ad5-bb26-141b45a5c0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7345\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(mean_squared_error(valid_y, y_pred))\n",
    "print(f'{valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e8a65-270a-4d1e-acc5-7b02074dbc74",
   "metadata": {},
   "source": [
    "Boom! We can see that compared to notebook 06 (whose validation loss was an astronomical number), we are seeing by adding an additional dimensionality reduction step and using the new features, we can increase the power of the simple linear regression a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff715e-c1db-44b6-bea9-f3178c0da06b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scikit-learn pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09ecf9-2a95-4788-8046-e81f0c87f4dd",
   "metadata": {},
   "source": [
    "As you can see, we have two model training steps (PCA and linear regression), and we called the train and transform/predict twice for each train and valid dataset. To deal with these sequential training/processing needs, Scikit-learn has a class called Pipeline that make this process more steamlined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f99e5145-85f7-4758-a697-50f0c90f0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a018fff-69dc-4f98-90e0-e131ccd94d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pca', PCA(n_components=10)), ('linear_model', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c361b169-6dc6-4159-903c-4a9980da1a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=10)),\n",
       "                (&#x27;linear_model&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=10)),\n",
       "                (&#x27;linear_model&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=10)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
       "                ('linear_model', LinearRegression())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bf64dbb-3f29-4a04-bd50-6c20d701a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7345\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(valid_X)\n",
    "loss = np.sqrt(mean_squared_error(valid_y, y_pred))\n",
    "print(f'{loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d45c640-763a-4f7b-bb0a-b770355a75b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549f74f-317b-4bd0-9983-006440434ae1",
   "metadata": {},
   "source": [
    "Previously, we have seen that the sales_lag feature was really important (which makes sense). Here we can also take a look at the model coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d63e313-7927-447e-8275-497f9b9fda21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.44882438e-01, -7.22625311e-02,  1.97460204e-01,  2.40064147e-03,\n",
       "        1.51658211e-03, -2.76771424e-04,  2.69603139e-02,  2.83471510e-02,\n",
       "       -4.12241914e-03, -3.54922333e-03])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce8a9c-7bcf-4ea5-96d9-7cab1314e9ed",
   "metadata": {},
   "source": [
    "The first variable has the highest importance by having the largest weight. However, how do we interpret the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db98e76c-b567-4975-a34d-0ee9c5fcd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_feature_explainability = pd.DataFrame(pca.components_.transpose(), \n",
    "                                          columns=[f'column_{i}' for i in range(1, 11)],\n",
    "                                          index=train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a79ff5f0-559d-4ff9-af5d-cfe5a617721e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales_lag          0.973549\n",
       "onpromotion_log    0.171278\n",
       "family_CLEANING    0.090983\n",
       "year_2016          0.031679\n",
       "quarter_4          0.014804\n",
       "Name: column_1, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_feature_explainability['column_1'].sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548aae8e-cdc2-4328-a827-893e2ec867e4",
   "metadata": {},
   "source": [
    "We can see that in the new feature, the first column (feature) is mostly comprised of sales_lag and onpromotion_log information. This suggest sales_lag still is most important indicator in the new model. (It is the most important contributor to the most important feature in the new model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e461e0-9fdd-4e82-bb48-bf7c3944e7e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c92666-8ac4-4789-a86f-9107afe32da7",
   "metadata": {},
   "source": [
    "1. Do you think dimensionality_reduction can also improve performance for Ridge, Lasso and RandomForestRegression? Why or why not? \n",
    "2. Repeat the training process using Ridge, Lasso and RandomForestRegression. Try different hyperparameters and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6707b82-d071-4186-b15c-8090c78592b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobleprog_training",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
