{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start building a model using the data we've created from the previous session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/Titanic/train_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to separate the training data (all the features) from the target (survival)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['Survived']\n",
    "x = train_df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((889, 9), (889,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we have discussed before, we need to split data into train/valid/test datasets. Here we need to split our training data into train/valid so we can evaluate our model performance on the validation dataset. \n",
    "\n",
    "You can do it by randomly setting aside 20% of data. Scikit-learn also provides a handy function for doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=88, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseDecisionTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A decision tree classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <tree>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\u001b[0m\n",
       "\u001b[0;34m        The function to measure the quality of a split. Supported criteria are\u001b[0m\n",
       "\u001b[0;34m        \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\u001b[0m\n",
       "\u001b[0;34m        Shannon information gain, see :ref:`tree_mathematical_formulation`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    splitter : {\"best\", \"random\"}, default=\"best\"\u001b[0m\n",
       "\u001b[0;34m        The strategy used to choose the split at each node. Supported\u001b[0m\n",
       "\u001b[0;34m        strategies are \"best\" to choose the best split and \"random\" to choose\u001b[0m\n",
       "\u001b[0;34m        the best random split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_depth : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The maximum depth of the tree. If None, then nodes are expanded until\u001b[0m\n",
       "\u001b[0;34m        all leaves are pure or until all leaves contain less than\u001b[0m\n",
       "\u001b[0;34m        min_samples_split samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_split : int or float, default=2\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to split an internal node:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_split` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_split` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_split * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_leaf : int or float, default=1\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to be at a leaf node.\u001b[0m\n",
       "\u001b[0;34m        A split point at any depth will only be considered if it leaves at\u001b[0m\n",
       "\u001b[0;34m        least ``min_samples_leaf`` training samples in each of the left and\u001b[0m\n",
       "\u001b[0;34m        right branches.  This may have the effect of smoothing the model,\u001b[0m\n",
       "\u001b[0;34m        especially in regression.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_leaf` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_leaf` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_leaf * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each node.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_weight_fraction_leaf : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        The minimum weighted fraction of the sum total of weights (of all\u001b[0m\n",
       "\u001b[0;34m        the input samples) required to be at a leaf node. Samples have\u001b[0m\n",
       "\u001b[0;34m        equal weight when sample_weight is not provided.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\u001b[0m\n",
       "\u001b[0;34m        The number of features to consider when looking for the best split:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            - If int, then consider `max_features` features at each split.\u001b[0m\n",
       "\u001b[0;34m            - If float, then `max_features` is a fraction and\u001b[0m\n",
       "\u001b[0;34m              `max(1, int(max_features * n_features_in_))` features are considered at\u001b[0m\n",
       "\u001b[0;34m              each split.\u001b[0m\n",
       "\u001b[0;34m            - If \"auto\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m            - If \"sqrt\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m            - If \"log2\", then `max_features=log2(n_features)`.\u001b[0m\n",
       "\u001b[0;34m            - If None, then `max_features=n_features`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            .. deprecated:: 1.1\u001b[0m\n",
       "\u001b[0;34m                The `\"auto\"` option was deprecated in 1.1 and will be removed\u001b[0m\n",
       "\u001b[0;34m                in 1.3.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note: the search for a split does not stop until at least one\u001b[0m\n",
       "\u001b[0;34m        valid partition of the node samples is found, even if it requires to\u001b[0m\n",
       "\u001b[0;34m        effectively inspect more than ``max_features`` features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int, RandomState instance or None, default=None\u001b[0m\n",
       "\u001b[0;34m        Controls the randomness of the estimator. The features are always\u001b[0m\n",
       "\u001b[0;34m        randomly permuted at each split, even if ``splitter`` is set to\u001b[0m\n",
       "\u001b[0;34m        ``\"best\"``. When ``max_features < n_features``, the algorithm will\u001b[0m\n",
       "\u001b[0;34m        select ``max_features`` at random at each split before finding the best\u001b[0m\n",
       "\u001b[0;34m        split among them. But the best found split may vary across different\u001b[0m\n",
       "\u001b[0;34m        runs, even if ``max_features=n_features``. That is the case, if the\u001b[0m\n",
       "\u001b[0;34m        improvement of the criterion is identical for several splits and one\u001b[0m\n",
       "\u001b[0;34m        split has to be selected at random. To obtain a deterministic behaviour\u001b[0m\n",
       "\u001b[0;34m        during fitting, ``random_state`` has to be fixed to an integer.\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_leaf_nodes : int, default=None\u001b[0m\n",
       "\u001b[0;34m        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\u001b[0m\n",
       "\u001b[0;34m        Best nodes are defined as relative reduction in impurity.\u001b[0m\n",
       "\u001b[0;34m        If None then unlimited number of leaf nodes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_impurity_decrease : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        A node will be split if this split induces a decrease of the impurity\u001b[0m\n",
       "\u001b[0;34m        greater than or equal to this value.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The weighted impurity decrease equation is the following::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            N_t / N * (impurity - N_t_R / N_t * right_impurity\u001b[0m\n",
       "\u001b[0;34m                                - N_t_L / N_t * left_impurity)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        where ``N`` is the total number of samples, ``N_t`` is the number of\u001b[0m\n",
       "\u001b[0;34m        samples at the current node, ``N_t_L`` is the number of samples in the\u001b[0m\n",
       "\u001b[0;34m        left child, and ``N_t_R`` is the number of samples in the right child.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\u001b[0m\n",
       "\u001b[0;34m        if ``sample_weight`` is passed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    class_weight : dict, list of dict or \"balanced\", default=None\u001b[0m\n",
       "\u001b[0;34m        Weights associated with classes in the form ``{class_label: weight}``.\u001b[0m\n",
       "\u001b[0;34m        If None, all classes are supposed to have weight one. For\u001b[0m\n",
       "\u001b[0;34m        multi-output problems, a list of dicts can be provided in the same\u001b[0m\n",
       "\u001b[0;34m        order as the columns of y.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that for multioutput (including multilabel) weights should be\u001b[0m\n",
       "\u001b[0;34m        defined for each class of every column in its own dict. For example,\u001b[0m\n",
       "\u001b[0;34m        for four-class multilabel classification weights should be\u001b[0m\n",
       "\u001b[0;34m        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\u001b[0m\n",
       "\u001b[0;34m        [{1:1}, {2:5}, {3:1}, {4:1}].\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The \"balanced\" mode uses the values of y to automatically adjust\u001b[0m\n",
       "\u001b[0;34m        weights inversely proportional to class frequencies in the input data\u001b[0m\n",
       "\u001b[0;34m        as ``n_samples / (n_classes * np.bincount(y))``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        For multi-output, the weights of each column of y will be multiplied.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that these weights will be multiplied with sample_weight (passed\u001b[0m\n",
       "\u001b[0;34m        through the fit method) if sample_weight is specified.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    ccp_alpha : non-negative float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        Complexity parameter used for Minimal Cost-Complexity Pruning. The\u001b[0m\n",
       "\u001b[0;34m        subtree with the largest cost complexity that is smaller than\u001b[0m\n",
       "\u001b[0;34m        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\u001b[0m\n",
       "\u001b[0;34m        :ref:`minimal_cost_complexity_pruning` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.22\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    classes_ : ndarray of shape (n_classes,) or list of ndarray\u001b[0m\n",
       "\u001b[0;34m        The classes labels (single output problem),\u001b[0m\n",
       "\u001b[0;34m        or a list of arrays of class labels (multi-output problem).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    feature_importances_ : ndarray of shape (n_features,)\u001b[0m\n",
       "\u001b[0;34m        The impurity-based feature importances.\u001b[0m\n",
       "\u001b[0;34m        The higher, the more important the feature.\u001b[0m\n",
       "\u001b[0;34m        The importance of a feature is computed as the (normalized)\u001b[0m\n",
       "\u001b[0;34m        total reduction of the criterion brought by that feature.  It is also\u001b[0m\n",
       "\u001b[0;34m        known as the Gini importance [4]_.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Warning: impurity-based feature importances can be misleading for\u001b[0m\n",
       "\u001b[0;34m        high cardinality features (many unique values). See\u001b[0m\n",
       "\u001b[0;34m        :func:`sklearn.inspection.permutation_importance` as an alternative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_features_ : int\u001b[0m\n",
       "\u001b[0;34m        The inferred value of max_features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_classes_ : int or list of int\u001b[0m\n",
       "\u001b[0;34m        The number of classes (for single output problems),\u001b[0m\n",
       "\u001b[0;34m        or a list containing the number of classes for each\u001b[0m\n",
       "\u001b[0;34m        output (for multi-output problems).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_features_in_ : int\u001b[0m\n",
       "\u001b[0;34m        Number of features seen during :term:`fit`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.24\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    feature_names_in_ : ndarray of shape (`n_features_in_`,)\u001b[0m\n",
       "\u001b[0;34m        Names of features seen during :term:`fit`. Defined only when `X`\u001b[0m\n",
       "\u001b[0;34m        has feature names that are all strings.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 1.0\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_outputs_ : int\u001b[0m\n",
       "\u001b[0;34m        The number of outputs when ``fit`` is performed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    tree_ : Tree instance\u001b[0m\n",
       "\u001b[0;34m        The underlying Tree object. Please refer to\u001b[0m\n",
       "\u001b[0;34m        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\u001b[0m\n",
       "\u001b[0;34m        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\u001b[0m\n",
       "\u001b[0;34m        for basic usage of these attributes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See Also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    DecisionTreeRegressor : A decision tree regressor.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    The default values for the parameters controlling the size of the trees\u001b[0m\n",
       "\u001b[0;34m    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\u001b[0m\n",
       "\u001b[0;34m    unpruned trees which can potentially be very large on some data sets. To\u001b[0m\n",
       "\u001b[0;34m    reduce memory consumption, the complexity and size of the trees should be\u001b[0m\n",
       "\u001b[0;34m    controlled by setting those parameter values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The :meth:`predict` method operates using the :func:`numpy.argmax`\u001b[0m\n",
       "\u001b[0;34m    function on the outputs of :meth:`predict_proba`. This means that in\u001b[0m\n",
       "\u001b[0;34m    case the highest predicted probabilities are tied, the classifier will\u001b[0m\n",
       "\u001b[0;34m    predict the tied class with the lowest index in :term:`classes_`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\u001b[0m\n",
       "\u001b[0;34m           and Regression Trees\", Wadsworth, Belmont, CA, 1984.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\u001b[0m\n",
       "\u001b[0;34m           Learning\", Springer, 2009.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\u001b[0m\n",
       "\u001b[0;34m           https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.datasets import load_iris\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.model_selection import cross_val_score\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.tree import DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m    >>> clf = DecisionTreeClassifier(random_state=0)\u001b[0m\n",
       "\u001b[0;34m    >>> iris = load_iris()\u001b[0m\n",
       "\u001b[0;34m    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\u001b[0m\n",
       "\u001b[0;34m    ...                             # doctest: +SKIP\u001b[0m\n",
       "\u001b[0;34m    ...\u001b[0m\n",
       "\u001b[0;34m    array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\u001b[0m\n",
       "\u001b[0;34m            0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mBaseDecisionTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"criterion\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStrOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"gini\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log_loss\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"class_weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStrOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mccp_alpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The training input samples. Internally, it will be converted to\u001b[0m\n",
       "\u001b[0;34m            ``dtype=np.float32`` and if a sparse matrix is provided\u001b[0m\n",
       "\u001b[0;34m            to a sparse ``csc_matrix``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\u001b[0m\n",
       "\u001b[0;34m            The target values (class labels) as integers or strings.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        sample_weight : array-like of shape (n_samples,), default=None\u001b[0m\n",
       "\u001b[0;34m            Sample weights. If None, then samples are equally weighted. Splits\u001b[0m\n",
       "\u001b[0;34m            that would create child nodes with net zero or negative weight are\u001b[0m\n",
       "\u001b[0;34m            ignored while searching for a split in each node. Splits are also\u001b[0m\n",
       "\u001b[0;34m            ignored if they would result in any single class carrying a\u001b[0m\n",
       "\u001b[0;34m            negative weight in either child node.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        check_input : bool, default=True\u001b[0m\n",
       "\u001b[0;34m            Allow to bypass several input checking.\u001b[0m\n",
       "\u001b[0;34m            Don't use this parameter unless you know what you're doing.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        self : DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m            Fitted estimator.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Predict class probabilities of the input samples X.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The predicted class probability is the fraction of samples of the same\u001b[0m\n",
       "\u001b[0;34m        class in a leaf.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The input samples. Internally, it will be converted to\u001b[0m\n",
       "\u001b[0;34m            ``dtype=np.float32`` and if a sparse matrix is provided\u001b[0m\n",
       "\u001b[0;34m            to a sparse ``csr_matrix``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        check_input : bool, default=True\u001b[0m\n",
       "\u001b[0;34m            Allow to bypass several input checking.\u001b[0m\n",
       "\u001b[0;34m            Don't use this parameter unless you know what you're doing.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\u001b[0m\n",
       "\u001b[0;34m            such arrays if n_outputs > 1\u001b[0m\n",
       "\u001b[0;34m            The class probabilities of the input samples. The order of the\u001b[0m\n",
       "\u001b[0;34m            classes corresponds to that in the attribute :term:`classes_`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnormalizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mproba\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mall_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mproba_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mnormalizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mproba_k\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mall_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Predict class log-probabilities of the input samples X.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            The input samples. Internally, it will be converted to\u001b[0m\n",
       "\u001b[0;34m            ``dtype=np.float32`` and if a sparse matrix is provided\u001b[0m\n",
       "\u001b[0;34m            to a sparse ``csr_matrix``.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\u001b[0m\n",
       "\u001b[0;34m            such arrays if n_outputs > 1\u001b[0m\n",
       "\u001b[0;34m            The class log-probabilities of the input samples. The order of the\u001b[0m\n",
       "\u001b[0;34m            classes corresponds to that in the attribute :term:`classes_`.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda/envs/nobleprog_training/lib/python3.10/site-packages/sklearn/tree/_classes.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     ExtraTreeClassifier\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by build a shallow tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = tree.DecisionTreeClassifier(max_depth = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_0.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452    1\n",
       "869    1\n",
       "641    0\n",
       "764    1\n",
       "695    0\n",
       "      ..\n",
       "43     1\n",
       "199    0\n",
       "95     0\n",
       "887    1\n",
       "343    0\n",
       "Name: Survived, Length: 711, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model_0.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({'pred': y_pred, 'label': y_valid})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tree.export_text(model_0, feature_names=list(x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Sex_numeric <= 0.50\n",
      "|   |--- Fare <= 26.27\n",
      "|   |   |--- class: 0\n",
      "|   |--- Fare >  26.27\n",
      "|   |   |--- class: 0\n",
      "|--- Sex_numeric >  0.50\n",
      "|   |--- Pclass <= 2.50\n",
      "|   |   |--- class: 1\n",
      "|   |--- Pclass >  2.50\n",
      "|   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.8333333333333334, 'Sex_numeric <= 0.5\\ngini = 0.472\\nsamples = 711\\nvalue = [439, 272]'),\n",
       " Text(0.25, 0.5, 'Fare <= 26.269\\ngini = 0.307\\nsamples = 454\\nvalue = [368, 86]'),\n",
       " Text(0.125, 0.16666666666666666, 'gini = 0.223\\nsamples = 329\\nvalue = [287, 42]'),\n",
       " Text(0.375, 0.16666666666666666, 'gini = 0.456\\nsamples = 125\\nvalue = [81, 44]'),\n",
       " Text(0.75, 0.5, 'Pclass <= 2.5\\ngini = 0.4\\nsamples = 257\\nvalue = [71, 186]'),\n",
       " Text(0.625, 0.16666666666666666, 'gini = 0.111\\nsamples = 136\\nvalue = [8, 128]'),\n",
       " Text(0.875, 0.16666666666666666, 'gini = 0.499\\nsamples = 121\\nvalue = [63, 58]')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(model_0, feature_names=list(x.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluting the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['TP'] = np.where((scores['pred'] == 1) & (scores['label'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['TN'] = np.where((scores['pred'] == 0) & (scores['label'] == 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['FP'] = np.where((scores['pred'] == 1) & (scores['label'] == 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['FN'] = np.where((scores['pred'] == 0) & (scores['label'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45588235294117646"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "scores['TP'].sum() / (scores['TP'].sum() + scores['FN'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96875"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "scores['TP'].sum() / (scores['TP'].sum() + scores['FP'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7865168539325843"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "(scores['TP'].sum() + scores['TN'].sum()) / len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn also has built-in functions that we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.65%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_valid, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall and f1 score on training dataset is 0.9411764705882353, 0.47058823529411764, 0.627450980392157\n",
      "precision, recall and f1 score on validation dataset is 0.96875, 0.45588235294117646, 0.62\n"
     ]
    }
   ],
   "source": [
    "precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average='binary')\n",
    "print(f\"precision, recall and f1 score on training dataset is {precision_train}, {recall_train}, {f1_train}\")\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(f\"precision, recall and f1 score on validation dataset is {precision}, {recall}, {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try other hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's make the tree more complex by adding one more level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tree.DecisionTreeClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1.predict(X_valid)\n",
    "train_pred = model_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall and f1 score on training dataset is 0.8894736842105263, 0.6213235294117647, 0.7316017316017316\n",
      "precision, recall and f1 score on validation dataset is 0.9130434782608695, 0.6176470588235294, 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average='binary')\n",
    "print(f\"precision, recall and f1 score on training dataset is {precision_train}, {recall_train}, {f1_train}\")\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(f\"precision, recall and f1 score on validation dataset is {precision}, {recall}, {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's make the tree even more complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall and f1 score on training dataset is 0.9478260869565217, 0.8014705882352942, 0.8685258964143425\n",
      "precision, recall and f1 score on validation dataset is 0.8775510204081632, 0.6323529411764706, 0.7350427350427351\n"
     ]
    }
   ],
   "source": [
    "model_2 = tree.DecisionTreeClassifier(max_depth=8)\n",
    "model_2.fit(X_train, y_train)\n",
    "y_pred = model_2.predict(X_valid)\n",
    "train_pred = model_2.predict(X_train)\n",
    "precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average='binary')\n",
    "print(f\"precision, recall and f1 score on training dataset is {precision_train}, {recall_train}, {f1_train}\")\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(f\"precision, recall and f1 score on validation dataset is {precision}, {recall}, {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 4, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [2, 4, 8], 'min_samples_split': [2, 4]}\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9130434782608695 0.6176470588235294 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "best_model = tree.DecisionTreeClassifier(max_depth=4, min_samples_split=2)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_valid)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(precision, recall, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobleprog_training",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
