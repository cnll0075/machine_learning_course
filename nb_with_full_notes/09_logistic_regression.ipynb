{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c35a56-5956-4a0a-a76f-23a7b2f546bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3616c9-db31-4038-8853-3054fe0c1c91",
   "metadata": {},
   "source": [
    "In this nb, we will run logistic regression on the processed titanic dataset and compare it's performance with the random forest. Previously the scores using default forest parameters are: \n",
    "- Precision: 0.8888888888888888 \n",
    "- Recall: 0.7058823529411765 \n",
    "- F1: 0.7868852459016393"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350a881-feda-4c45-93fb-f3d8b4224400",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "461cb848-c6ec-4d80-9a81-81bbe570d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/Titanic/train_processed.csv\")\n",
    "y = train_df['Survived']\n",
    "x = train_df.drop(['Survived'], axis=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=23, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628773b4-e38c-497a-a8ce-728d2c66088d",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862bd79-2e14-4eb6-b30a-5a50ad919bb9",
   "metadata": {},
   "source": [
    "- Train the model using an l2 regularization. \n",
    "- Get the prediction labels for the validationn dataset. \n",
    "- Evaluate precision, recall and f1 score.\n",
    "- Can you find how to get the predicted probability in addtion to just the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507e1f57-d09c-4210-8cf6-3116e15e6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0d64d3-29e5-4856-b544-41c4e4cae5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression('l2', max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8d9eb4-a95f-431e-875b-4715b4daf5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d263f1b6-593e-430d-948e-542b90744945",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d79fd9b2-3fba-4eea-a546-8db18516616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8032786885245902, 0.7205882352941176, 0.7596899224806202, None)\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_fscore_support(y_valid, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dce9da4-6777-4008-a48b-20b7aefbfb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34066061, 0.65933939],\n",
       "       [0.90371643, 0.09628357],\n",
       "       [0.06090852, 0.93909148],\n",
       "       [0.92321411, 0.07678589],\n",
       "       [0.93438658, 0.06561342],\n",
       "       [0.43335694, 0.56664306],\n",
       "       [0.87849928, 0.12150072],\n",
       "       [0.15350256, 0.84649744],\n",
       "       [0.9162111 , 0.0837889 ],\n",
       "       [0.09779418, 0.90220582],\n",
       "       [0.89686385, 0.10313615],\n",
       "       [0.68948172, 0.31051828],\n",
       "       [0.29969849, 0.70030151],\n",
       "       [0.30047974, 0.69952026],\n",
       "       [0.26658014, 0.73341986],\n",
       "       [0.26295373, 0.73704627],\n",
       "       [0.50954053, 0.49045947],\n",
       "       [0.97806543, 0.02193457],\n",
       "       [0.86822374, 0.13177626],\n",
       "       [0.95449532, 0.04550468],\n",
       "       [0.59456526, 0.40543474],\n",
       "       [0.85032641, 0.14967359],\n",
       "       [0.8102076 , 0.1897924 ],\n",
       "       [0.97570235, 0.02429765],\n",
       "       [0.76336013, 0.23663987],\n",
       "       [0.03794788, 0.96205212],\n",
       "       [0.12507153, 0.87492847],\n",
       "       [0.87829348, 0.12170652],\n",
       "       [0.42197615, 0.57802385],\n",
       "       [0.89853871, 0.10146129],\n",
       "       [0.51646052, 0.48353948],\n",
       "       [0.20997101, 0.79002899],\n",
       "       [0.74564384, 0.25435616],\n",
       "       [0.80793077, 0.19206923],\n",
       "       [0.9480174 , 0.0519826 ],\n",
       "       [0.93010802, 0.06989198],\n",
       "       [0.92332922, 0.07667078],\n",
       "       [0.91277779, 0.08722221],\n",
       "       [0.85032728, 0.14967272],\n",
       "       [0.79397655, 0.20602345],\n",
       "       [0.87345554, 0.12654446],\n",
       "       [0.49149301, 0.50850699],\n",
       "       [0.90111483, 0.09888517],\n",
       "       [0.83981006, 0.16018994],\n",
       "       [0.93306804, 0.06693196],\n",
       "       [0.12164596, 0.87835404],\n",
       "       [0.68951646, 0.31048354],\n",
       "       [0.0563645 , 0.9436355 ],\n",
       "       [0.03528643, 0.96471357],\n",
       "       [0.86276555, 0.13723445],\n",
       "       [0.72334615, 0.27665385],\n",
       "       [0.86832209, 0.13167791],\n",
       "       [0.88046376, 0.11953624],\n",
       "       [0.23287532, 0.76712468],\n",
       "       [0.41068892, 0.58931108],\n",
       "       [0.86470847, 0.13529153],\n",
       "       [0.89690285, 0.10309715],\n",
       "       [0.91280311, 0.08719689],\n",
       "       [0.23796851, 0.76203149],\n",
       "       [0.55590977, 0.44409023],\n",
       "       [0.44266675, 0.55733325],\n",
       "       [0.96281822, 0.03718178],\n",
       "       [0.903943  , 0.096057  ],\n",
       "       [0.85698244, 0.14301756],\n",
       "       [0.86272145, 0.13727855],\n",
       "       [0.06899987, 0.93100013],\n",
       "       [0.69848745, 0.30151255],\n",
       "       [0.42607634, 0.57392366],\n",
       "       [0.26999669, 0.73000331],\n",
       "       [0.38169401, 0.61830599],\n",
       "       [0.78387549, 0.21612451],\n",
       "       [0.62130693, 0.37869307],\n",
       "       [0.52391273, 0.47608727],\n",
       "       [0.64335591, 0.35664409],\n",
       "       [0.87515307, 0.12484693],\n",
       "       [0.89688516, 0.10311484],\n",
       "       [0.82333572, 0.17666428],\n",
       "       [0.63141963, 0.36858037],\n",
       "       [0.50771305, 0.49228695],\n",
       "       [0.84312707, 0.15687293],\n",
       "       [0.7447182 , 0.2552818 ],\n",
       "       [0.30428662, 0.69571338],\n",
       "       [0.86299305, 0.13700695],\n",
       "       [0.76939134, 0.23060866],\n",
       "       [0.19394353, 0.80605647],\n",
       "       [0.76279244, 0.23720756],\n",
       "       [0.90392124, 0.09607876],\n",
       "       [0.33426151, 0.66573849],\n",
       "       [0.90392124, 0.09607876],\n",
       "       [0.32310534, 0.67689466],\n",
       "       [0.9009116 , 0.0990884 ],\n",
       "       [0.92752273, 0.07247727],\n",
       "       [0.39404414, 0.60595586],\n",
       "       [0.43894428, 0.56105572],\n",
       "       [0.24437581, 0.75562419],\n",
       "       [0.40389991, 0.59610009],\n",
       "       [0.76336013, 0.23663987],\n",
       "       [0.08824695, 0.91175305],\n",
       "       [0.90630351, 0.09369649],\n",
       "       [0.4580754 , 0.5419246 ],\n",
       "       [0.85662023, 0.14337977],\n",
       "       [0.13974415, 0.86025585],\n",
       "       [0.36132884, 0.63867116],\n",
       "       [0.62721446, 0.37278554],\n",
       "       [0.90630351, 0.09369649],\n",
       "       [0.35739065, 0.64260935],\n",
       "       [0.86703808, 0.13296192],\n",
       "       [0.74474064, 0.25525936],\n",
       "       [0.94800739, 0.05199261],\n",
       "       [0.90512351, 0.09487649],\n",
       "       [0.68951646, 0.31048354],\n",
       "       [0.85316177, 0.14683823],\n",
       "       [0.21591086, 0.78408914],\n",
       "       [0.95024125, 0.04975875],\n",
       "       [0.06168513, 0.93831487],\n",
       "       [0.77912737, 0.22087263],\n",
       "       [0.7091682 , 0.2908318 ],\n",
       "       [0.77752989, 0.22247011],\n",
       "       [0.38870621, 0.61129379],\n",
       "       [0.91641099, 0.08358901],\n",
       "       [0.90403408, 0.09596592],\n",
       "       [0.88803915, 0.11196085],\n",
       "       [0.9137319 , 0.0862681 ],\n",
       "       [0.86286331, 0.13713669],\n",
       "       [0.04474744, 0.95525256],\n",
       "       [0.37248156, 0.62751844],\n",
       "       [0.89557801, 0.10442199],\n",
       "       [0.24888248, 0.75111752],\n",
       "       [0.93392814, 0.06607186],\n",
       "       [0.86468946, 0.13531054],\n",
       "       [0.41475674, 0.58524326],\n",
       "       [0.943296  , 0.056704  ],\n",
       "       [0.85032641, 0.14967359],\n",
       "       [0.91642603, 0.08357397],\n",
       "       [0.23262486, 0.76737514],\n",
       "       [0.86485652, 0.13514348],\n",
       "       [0.13458257, 0.86541743],\n",
       "       [0.17991263, 0.82008737],\n",
       "       [0.90383477, 0.09616523],\n",
       "       [0.85149325, 0.14850675],\n",
       "       [0.04958047, 0.95041953],\n",
       "       [0.77928407, 0.22071593],\n",
       "       [0.2947263 , 0.7052737 ],\n",
       "       [0.86825241, 0.13174759],\n",
       "       [0.64821408, 0.35178592],\n",
       "       [0.30523392, 0.69476608],\n",
       "       [0.88791018, 0.11208982],\n",
       "       [0.76336013, 0.23663987],\n",
       "       [0.28798432, 0.71201568],\n",
       "       [0.11520108, 0.88479892],\n",
       "       [0.45041366, 0.54958634],\n",
       "       [0.88333535, 0.11666465],\n",
       "       [0.33374007, 0.66625993],\n",
       "       [0.82507669, 0.17492331],\n",
       "       [0.04131345, 0.95868655],\n",
       "       [0.61580958, 0.38419042],\n",
       "       [0.91986921, 0.08013079],\n",
       "       [0.94080824, 0.05919176],\n",
       "       [0.88347691, 0.11652309],\n",
       "       [0.86289215, 0.13710785],\n",
       "       [0.20232551, 0.79767449],\n",
       "       [0.77849981, 0.22150019],\n",
       "       [0.85209046, 0.14790954],\n",
       "       [0.33375966, 0.66624034],\n",
       "       [0.69986239, 0.30013761],\n",
       "       [0.06542619, 0.93457381],\n",
       "       [0.65684387, 0.34315613],\n",
       "       [0.89467758, 0.10532242],\n",
       "       [0.50338729, 0.49661271],\n",
       "       [0.96748041, 0.03251959],\n",
       "       [0.15978769, 0.84021231],\n",
       "       [0.71893952, 0.28106048],\n",
       "       [0.91048203, 0.08951797],\n",
       "       [0.28505865, 0.71494135],\n",
       "       [0.87882463, 0.12117537],\n",
       "       [0.90392124, 0.09607876],\n",
       "       [0.7513277 , 0.2486723 ],\n",
       "       [0.86155649, 0.13844351]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c08a6-861e-4166-bfb7-5b1f9fad7283",
   "metadata": {},
   "source": [
    "There's a mysterious new parameter for logistic_regression: Solver..what is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05028838-f222-4591-a663-999d7e718ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobleprog_training",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
