{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous notebook, we split our data into the same train and validation subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df = pd.read_csv(\"../data/Titanic/train_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['Survived']\n",
    "x = train_df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=23, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mForestClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    A random forest classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    A random forest is a meta estimator that fits a number of decision tree\u001b[0m\n",
       "\u001b[0;34m    classifiers on various sub-samples of the dataset and uses averaging to\u001b[0m\n",
       "\u001b[0;34m    improve the predictive accuracy and control over-fitting.\u001b[0m\n",
       "\u001b[0;34m    The sub-sample size is controlled with the `max_samples` parameter if\u001b[0m\n",
       "\u001b[0;34m    `bootstrap=True` (default), otherwise the whole dataset is used to build\u001b[0m\n",
       "\u001b[0;34m    each tree.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <forest>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    n_estimators : int, default=100\u001b[0m\n",
       "\u001b[0;34m        The number of trees in the forest.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.22\u001b[0m\n",
       "\u001b[0;34m           The default value of ``n_estimators`` changed from 10 to 100\u001b[0m\n",
       "\u001b[0;34m           in 0.22.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\u001b[0m\n",
       "\u001b[0;34m        The function to measure the quality of a split. Supported criteria are\u001b[0m\n",
       "\u001b[0;34m        \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\u001b[0m\n",
       "\u001b[0;34m        Shannon information gain, see :ref:`tree_mathematical_formulation`.\u001b[0m\n",
       "\u001b[0;34m        Note: This parameter is tree-specific.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_depth : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The maximum depth of the tree. If None, then nodes are expanded until\u001b[0m\n",
       "\u001b[0;34m        all leaves are pure or until all leaves contain less than\u001b[0m\n",
       "\u001b[0;34m        min_samples_split samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_split : int or float, default=2\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to split an internal node:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_split` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_split` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_split * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_leaf : int or float, default=1\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to be at a leaf node.\u001b[0m\n",
       "\u001b[0;34m        A split point at any depth will only be considered if it leaves at\u001b[0m\n",
       "\u001b[0;34m        least ``min_samples_leaf`` training samples in each of the left and\u001b[0m\n",
       "\u001b[0;34m        right branches.  This may have the effect of smoothing the model,\u001b[0m\n",
       "\u001b[0;34m        especially in regression.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_leaf` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_leaf` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_leaf * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each node.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_weight_fraction_leaf : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        The minimum weighted fraction of the sum total of weights (of all\u001b[0m\n",
       "\u001b[0;34m        the input samples) required to be at a leaf node. Samples have\u001b[0m\n",
       "\u001b[0;34m        equal weight when sample_weight is not provided.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\u001b[0m\n",
       "\u001b[0;34m        The number of features to consider when looking for the best split:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `max_features` features at each split.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `max_features` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `max(1, int(max_features * n_features_in_))` features are considered at each\u001b[0m\n",
       "\u001b[0;34m          split.\u001b[0m\n",
       "\u001b[0;34m        - If \"auto\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m        - If \"sqrt\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m        - If \"log2\", then `max_features=log2(n_features)`.\u001b[0m\n",
       "\u001b[0;34m        - If None, then `max_features=n_features`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 1.1\u001b[0m\n",
       "\u001b[0;34m            The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. deprecated:: 1.1\u001b[0m\n",
       "\u001b[0;34m            The `\"auto\"` option was deprecated in 1.1 and will be removed\u001b[0m\n",
       "\u001b[0;34m            in 1.3.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note: the search for a split does not stop until at least one\u001b[0m\n",
       "\u001b[0;34m        valid partition of the node samples is found, even if it requires to\u001b[0m\n",
       "\u001b[0;34m        effectively inspect more than ``max_features`` features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_leaf_nodes : int, default=None\u001b[0m\n",
       "\u001b[0;34m        Grow trees with ``max_leaf_nodes`` in best-first fashion.\u001b[0m\n",
       "\u001b[0;34m        Best nodes are defined as relative reduction in impurity.\u001b[0m\n",
       "\u001b[0;34m        If None then unlimited number of leaf nodes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_impurity_decrease : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        A node will be split if this split induces a decrease of the impurity\u001b[0m\n",
       "\u001b[0;34m        greater than or equal to this value.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The weighted impurity decrease equation is the following::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            N_t / N * (impurity - N_t_R / N_t * right_impurity\u001b[0m\n",
       "\u001b[0;34m                                - N_t_L / N_t * left_impurity)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        where ``N`` is the total number of samples, ``N_t`` is the number of\u001b[0m\n",
       "\u001b[0;34m        samples at the current node, ``N_t_L`` is the number of samples in the\u001b[0m\n",
       "\u001b[0;34m        left child, and ``N_t_R`` is the number of samples in the right child.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\u001b[0m\n",
       "\u001b[0;34m        if ``sample_weight`` is passed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    bootstrap : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        Whether bootstrap samples are used when building trees. If False, the\u001b[0m\n",
       "\u001b[0;34m        whole dataset is used to build each tree.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    oob_score : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        Whether to use out-of-bag samples to estimate the generalization score.\u001b[0m\n",
       "\u001b[0;34m        Only available if bootstrap=True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_jobs : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\u001b[0m\n",
       "\u001b[0;34m        :meth:`decision_path` and :meth:`apply` are all parallelized over the\u001b[0m\n",
       "\u001b[0;34m        trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\u001b[0m\n",
       "\u001b[0;34m        context. ``-1`` means using all processors. See :term:`Glossary\u001b[0m\n",
       "\u001b[0;34m        <n_jobs>` for more details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int, RandomState instance or None, default=None\u001b[0m\n",
       "\u001b[0;34m        Controls both the randomness of the bootstrapping of the samples used\u001b[0m\n",
       "\u001b[0;34m        when building trees (if ``bootstrap=True``) and the sampling of the\u001b[0m\n",
       "\u001b[0;34m        features to consider when looking for the best split at each node\u001b[0m\n",
       "\u001b[0;34m        (if ``max_features < n_features``).\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    verbose : int, default=0\u001b[0m\n",
       "\u001b[0;34m        Controls the verbosity when fitting and predicting.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    warm_start : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        When set to ``True``, reuse the solution of the previous call to fit\u001b[0m\n",
       "\u001b[0;34m        and add more estimators to the ensemble, otherwise, just fit a whole\u001b[0m\n",
       "\u001b[0;34m        new forest. See :term:`Glossary <warm_start>` and\u001b[0m\n",
       "\u001b[0;34m        :ref:`gradient_boosting_warm_start` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts, \\\u001b[0m\n",
       "\u001b[0;34m            default=None\u001b[0m\n",
       "\u001b[0;34m        Weights associated with classes in the form ``{class_label: weight}``.\u001b[0m\n",
       "\u001b[0;34m        If not given, all classes are supposed to have weight one. For\u001b[0m\n",
       "\u001b[0;34m        multi-output problems, a list of dicts can be provided in the same\u001b[0m\n",
       "\u001b[0;34m        order as the columns of y.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that for multioutput (including multilabel) weights should be\u001b[0m\n",
       "\u001b[0;34m        defined for each class of every column in its own dict. For example,\u001b[0m\n",
       "\u001b[0;34m        for four-class multilabel classification weights should be\u001b[0m\n",
       "\u001b[0;34m        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\u001b[0m\n",
       "\u001b[0;34m        [{1:1}, {2:5}, {3:1}, {4:1}].\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The \"balanced\" mode uses the values of y to automatically adjust\u001b[0m\n",
       "\u001b[0;34m        weights inversely proportional to class frequencies in the input data\u001b[0m\n",
       "\u001b[0;34m        as ``n_samples / (n_classes * np.bincount(y))``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The \"balanced_subsample\" mode is the same as \"balanced\" except that\u001b[0m\n",
       "\u001b[0;34m        weights are computed based on the bootstrap sample for every tree\u001b[0m\n",
       "\u001b[0;34m        grown.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        For multi-output, the weights of each column of y will be multiplied.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that these weights will be multiplied with sample_weight (passed\u001b[0m\n",
       "\u001b[0;34m        through the fit method) if sample_weight is specified.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    ccp_alpha : non-negative float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        Complexity parameter used for Minimal Cost-Complexity Pruning. The\u001b[0m\n",
       "\u001b[0;34m        subtree with the largest cost complexity that is smaller than\u001b[0m\n",
       "\u001b[0;34m        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\u001b[0m\n",
       "\u001b[0;34m        :ref:`minimal_cost_complexity_pruning` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.22\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_samples : int or float, default=None\u001b[0m\n",
       "\u001b[0;34m        If bootstrap is True, the number of samples to draw from X\u001b[0m\n",
       "\u001b[0;34m        to train each base estimator.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If None (default), then draw `X.shape[0]` samples.\u001b[0m\n",
       "\u001b[0;34m        - If int, then draw `max_samples` samples.\u001b[0m\n",
       "\u001b[0;34m        - If float, then draw `max_samples * X.shape[0]` samples. Thus,\u001b[0m\n",
       "\u001b[0;34m          `max_samples` should be in the interval `(0.0, 1.0]`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.22\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\u001b[0m\n",
       "\u001b[0;34m        The child estimator template used to create the collection of fitted\u001b[0m\n",
       "\u001b[0;34m        sub-estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 1.2\u001b[0m\n",
       "\u001b[0;34m           `base_estimator_` was renamed to `estimator_`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    base_estimator_ : DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m        The child estimator template used to create the collection of fitted\u001b[0m\n",
       "\u001b[0;34m        sub-estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. deprecated:: 1.2\u001b[0m\n",
       "\u001b[0;34m            `base_estimator_` is deprecated and will be removed in 1.4.\u001b[0m\n",
       "\u001b[0;34m            Use `estimator_` instead.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    estimators_ : list of DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m        The collection of fitted sub-estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    classes_ : ndarray of shape (n_classes,) or a list of such arrays\u001b[0m\n",
       "\u001b[0;34m        The classes labels (single output problem), or a list of arrays of\u001b[0m\n",
       "\u001b[0;34m        class labels (multi-output problem).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_classes_ : int or list\u001b[0m\n",
       "\u001b[0;34m        The number of classes (single output problem), or a list containing the\u001b[0m\n",
       "\u001b[0;34m        number of classes for each output (multi-output problem).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_features_in_ : int\u001b[0m\n",
       "\u001b[0;34m        Number of features seen during :term:`fit`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.24\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    feature_names_in_ : ndarray of shape (`n_features_in_`,)\u001b[0m\n",
       "\u001b[0;34m        Names of features seen during :term:`fit`. Defined only when `X`\u001b[0m\n",
       "\u001b[0;34m        has feature names that are all strings.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 1.0\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_outputs_ : int\u001b[0m\n",
       "\u001b[0;34m        The number of outputs when ``fit`` is performed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    feature_importances_ : ndarray of shape (n_features,)\u001b[0m\n",
       "\u001b[0;34m        The impurity-based feature importances.\u001b[0m\n",
       "\u001b[0;34m        The higher, the more important the feature.\u001b[0m\n",
       "\u001b[0;34m        The importance of a feature is computed as the (normalized)\u001b[0m\n",
       "\u001b[0;34m        total reduction of the criterion brought by that feature.  It is also\u001b[0m\n",
       "\u001b[0;34m        known as the Gini importance.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Warning: impurity-based feature importances can be misleading for\u001b[0m\n",
       "\u001b[0;34m        high cardinality features (many unique values). See\u001b[0m\n",
       "\u001b[0;34m        :func:`sklearn.inspection.permutation_importance` as an alternative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    oob_score_ : float\u001b[0m\n",
       "\u001b[0;34m        Score of the training dataset obtained using an out-of-bag estimate.\u001b[0m\n",
       "\u001b[0;34m        This attribute exists only when ``oob_score`` is True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    oob_decision_function_ : ndarray of shape (n_samples, n_classes) or \\\u001b[0m\n",
       "\u001b[0;34m            (n_samples, n_classes, n_outputs)\u001b[0m\n",
       "\u001b[0;34m        Decision function computed with out-of-bag estimate on the training\u001b[0m\n",
       "\u001b[0;34m        set. If n_estimators is small it might be possible that a data point\u001b[0m\n",
       "\u001b[0;34m        was never left out during the bootstrap. In this case,\u001b[0m\n",
       "\u001b[0;34m        `oob_decision_function_` might contain NaN. This attribute exists\u001b[0m\n",
       "\u001b[0;34m        only when ``oob_score`` is True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See Also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\u001b[0m\n",
       "\u001b[0;34m    sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\u001b[0m\n",
       "\u001b[0;34m        tree classifiers.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    The default values for the parameters controlling the size of the trees\u001b[0m\n",
       "\u001b[0;34m    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\u001b[0m\n",
       "\u001b[0;34m    unpruned trees which can potentially be very large on some data sets. To\u001b[0m\n",
       "\u001b[0;34m    reduce memory consumption, the complexity and size of the trees should be\u001b[0m\n",
       "\u001b[0;34m    controlled by setting those parameter values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The features are always randomly permuted at each split. Therefore,\u001b[0m\n",
       "\u001b[0;34m    the best found split may vary, even with the same training data,\u001b[0m\n",
       "\u001b[0;34m    ``max_features=n_features`` and ``bootstrap=False``, if the improvement\u001b[0m\n",
       "\u001b[0;34m    of the criterion is identical for several splits enumerated during the\u001b[0m\n",
       "\u001b[0;34m    search of the best split. To obtain a deterministic behaviour during\u001b[0m\n",
       "\u001b[0;34m    fitting, ``random_state`` has to be fixed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.ensemble import RandomForestClassifier\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.datasets import make_classification\u001b[0m\n",
       "\u001b[0;34m    >>> X, y = make_classification(n_samples=1000, n_features=4,\u001b[0m\n",
       "\u001b[0;34m    ...                            n_informative=2, n_redundant=0,\u001b[0m\n",
       "\u001b[0;34m    ...                            random_state=0, shuffle=False)\u001b[0m\n",
       "\u001b[0;34m    >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\u001b[0m\n",
       "\u001b[0;34m    >>> clf.fit(X, y)\u001b[0m\n",
       "\u001b[0;34m    RandomForestClassifier(...)\u001b[0m\n",
       "\u001b[0;34m    >>> print(clf.predict([[0, 0, 0, 0]]))\u001b[0m\n",
       "\u001b[0;34m    [1]\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mForestClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"class_weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mStrOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"balanced_subsample\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"splitter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sqrt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mestimator_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"criterion\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"max_depth\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_samples_split\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_samples_leaf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_weight_fraction_leaf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"max_leaf_nodes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_impurity_decrease\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"random_state\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"ccp_alpha\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moob_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mccp_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mccp_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda/envs/nobleprog_training/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=10,\n",
    "                               max_samples = 0.7,\n",
    "                               max_features= 0.8,\n",
    "                               max_depth=3,\n",
    "                               min_samples_split=2,\n",
    "                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, max_features=0.8, max_samples=0.7,\n",
       "                       n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, max_features=0.8, max_samples=0.7,\n",
       "                       n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, max_features=0.8, max_samples=0.7,\n",
       "                       n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103448275862069 0.6911764705882353 0.746031746031746\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz: can you try using grid search to find the best n_estimator, max_samples, and max_features?\n",
    "\n",
    "Hint: refer to the previous nb to find how to do grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 7, 'max_features': 0.6, 'max_samples': 0.9, 'min_samples_split': 3, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators': [5, 10, 15], 'max_features': [0.6, 0.8],\n",
    "              'max_samples': [0.7, 0.9], 'max_depth': [3, 5, 7], 'min_samples_split':[1, 2,3]}\n",
    "\n",
    "model = RandomForestClassifier(random_state=125)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='f1')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859 0.7647058823529411 0.8319999999999999\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(precision, recall, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13576327, 0.15115305, 0.03808415, 0.05235727, 0.22139248,\n",
       "       0.34980156, 0.01701962, 0.00357967, 0.03084891])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=feature_imp, y=feature_imp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobleprog_training",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
