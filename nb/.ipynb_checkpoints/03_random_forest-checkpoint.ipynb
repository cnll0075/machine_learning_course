{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous notebook, we split our data into the same train and validation subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df = pd.read_csv(\"../data/Titanic/train_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['Survived']\n",
    "x = train_df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=23, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mForestClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    A random forest classifier.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    A random forest is a meta estimator that fits a number of decision tree\u001b[0m\n",
       "\u001b[0;34m    classifiers on various sub-samples of the dataset and uses averaging to\u001b[0m\n",
       "\u001b[0;34m    improve the predictive accuracy and control over-fitting.\u001b[0m\n",
       "\u001b[0;34m    The sub-sample size is controlled with the `max_samples` parameter if\u001b[0m\n",
       "\u001b[0;34m    `bootstrap=True` (default), otherwise the whole dataset is used to build\u001b[0m\n",
       "\u001b[0;34m    each tree.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <forest>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    n_estimators : int, default=100\u001b[0m\n",
       "\u001b[0;34m        The number of trees in the forest.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.22\u001b[0m\n",
       "\u001b[0;34m           The default value of ``n_estimators`` changed from 10 to 100\u001b[0m\n",
       "\u001b[0;34m           in 0.22.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\u001b[0m\n",
       "\u001b[0;34m        The function to measure the quality of a split. Supported criteria are\u001b[0m\n",
       "\u001b[0;34m        \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\u001b[0m\n",
       "\u001b[0;34m        Shannon information gain, see :ref:`tree_mathematical_formulation`.\u001b[0m\n",
       "\u001b[0;34m        Note: This parameter is tree-specific.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_depth : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The maximum depth of the tree. If None, then nodes are expanded until\u001b[0m\n",
       "\u001b[0;34m        all leaves are pure or until all leaves contain less than\u001b[0m\n",
       "\u001b[0;34m        min_samples_split samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_split : int or float, default=2\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to split an internal node:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_split` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_split` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_split * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each split.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_samples_leaf : int or float, default=1\u001b[0m\n",
       "\u001b[0;34m        The minimum number of samples required to be at a leaf node.\u001b[0m\n",
       "\u001b[0;34m        A split point at any depth will only be considered if it leaves at\u001b[0m\n",
       "\u001b[0;34m        least ``min_samples_leaf`` training samples in each of the left and\u001b[0m\n",
       "\u001b[0;34m        right branches.  This may have the effect of smoothing the model,\u001b[0m\n",
       "\u001b[0;34m        especially in regression.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `min_samples_leaf` as the minimum number.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `min_samples_leaf` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `ceil(min_samples_leaf * n_samples)` are the minimum\u001b[0m\n",
       "\u001b[0;34m          number of samples for each node.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 0.18\u001b[0m\n",
       "\u001b[0;34m           Added float values for fractions.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_weight_fraction_leaf : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        The minimum weighted fraction of the sum total of weights (of all\u001b[0m\n",
       "\u001b[0;34m        the input samples) required to be at a leaf node. Samples have\u001b[0m\n",
       "\u001b[0;34m        equal weight when sample_weight is not provided.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\u001b[0m\n",
       "\u001b[0;34m        The number of features to consider when looking for the best split:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If int, then consider `max_features` features at each split.\u001b[0m\n",
       "\u001b[0;34m        - If float, then `max_features` is a fraction and\u001b[0m\n",
       "\u001b[0;34m          `max(1, int(max_features * n_features_in_))` features are considered at each\u001b[0m\n",
       "\u001b[0;34m          split.\u001b[0m\n",
       "\u001b[0;34m        - If \"auto\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m        - If \"sqrt\", then `max_features=sqrt(n_features)`.\u001b[0m\n",
       "\u001b[0;34m        - If \"log2\", then `max_features=log2(n_features)`.\u001b[0m\n",
       "\u001b[0;34m        - If None, then `max_features=n_features`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionchanged:: 1.1\u001b[0m\n",
       "\u001b[0;34m            The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. deprecated:: 1.1\u001b[0m\n",
       "\u001b[0;34m            The `\"auto\"` option was deprecated in 1.1 and will be removed\u001b[0m\n",
       "\u001b[0;34m            in 1.3.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note: the search for a split does not stop until at least one\u001b[0m\n",
       "\u001b[0;34m        valid partition of the node samples is found, even if it requires to\u001b[0m\n",
       "\u001b[0;34m        effectively inspect more than ``max_features`` features.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_leaf_nodes : int, default=None\u001b[0m\n",
       "\u001b[0;34m        Grow trees with ``max_leaf_nodes`` in best-first fashion.\u001b[0m\n",
       "\u001b[0;34m        Best nodes are defined as relative reduction in impurity.\u001b[0m\n",
       "\u001b[0;34m        If None then unlimited number of leaf nodes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    min_impurity_decrease : float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        A node will be split if this split induces a decrease of the impurity\u001b[0m\n",
       "\u001b[0;34m        greater than or equal to this value.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The weighted impurity decrease equation is the following::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            N_t / N * (impurity - N_t_R / N_t * right_impurity\u001b[0m\n",
       "\u001b[0;34m                                - N_t_L / N_t * left_impurity)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        where ``N`` is the total number of samples, ``N_t`` is the number of\u001b[0m\n",
       "\u001b[0;34m        samples at the current node, ``N_t_L`` is the number of samples in the\u001b[0m\n",
       "\u001b[0;34m        left child, and ``N_t_R`` is the number of samples in the right child.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\u001b[0m\n",
       "\u001b[0;34m        if ``sample_weight`` is passed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    bootstrap : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        Whether bootstrap samples are used when building trees. If False, the\u001b[0m\n",
       "\u001b[0;34m        whole dataset is used to build each tree.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    oob_score : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        Whether to use out-of-bag samples to estimate the generalization score.\u001b[0m\n",
       "\u001b[0;34m        Only available if bootstrap=True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_jobs : int, default=None\u001b[0m\n",
       "\u001b[0;34m        The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\u001b[0m\n",
       "\u001b[0;34m        :meth:`decision_path` and :meth:`apply` are all parallelized over the\u001b[0m\n",
       "\u001b[0;34m        trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\u001b[0m\n",
       "\u001b[0;34m        context. ``-1`` means using all processors. See :term:`Glossary\u001b[0m\n",
       "\u001b[0;34m        <n_jobs>` for more details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int, RandomState instance or None, default=None\u001b[0m\n",
       "\u001b[0;34m        Controls both the randomness of the bootstrapping of the samples used\u001b[0m\n",
       "\u001b[0;34m        when building trees (if ``bootstrap=True``) and the sampling of the\u001b[0m\n",
       "\u001b[0;34m        features to consider when looking for the best split at each node\u001b[0m\n",
       "\u001b[0;34m        (if ``max_features < n_features``).\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    verbose : int, default=0\u001b[0m\n",
       "\u001b[0;34m        Controls the verbosity when fitting and predicting.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    warm_start : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        When set to ``True``, reuse the solution of the previous call to fit\u001b[0m\n",
       "\u001b[0;34m        and add more estimators to the ensemble, otherwise, just fit a whole\u001b[0m\n",
       "\u001b[0;34m        new forest. See :term:`Glossary <warm_start>` and\u001b[0m\n",
       "\u001b[0;34m        :ref:`gradient_boosting_warm_start` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts, \\\u001b[0m\n",
       "\u001b[0;34m            default=None\u001b[0m\n",
       "\u001b[0;34m        Weights associated with classes in the form ``{class_label: weight}``.\u001b[0m\n",
       "\u001b[0;34m        If not given, all classes are supposed to have weight one. For\u001b[0m\n",
       "\u001b[0;34m        multi-output problems, a list of dicts can be provided in the same\u001b[0m\n",
       "\u001b[0;34m        order as the columns of y.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that for multioutput (including multilabel) weights should be\u001b[0m\n",
       "\u001b[0;34m        defined for each class of every column in its own dict. For example,\u001b[0m\n",
       "\u001b[0;34m        for four-class multilabel classification weights should be\u001b[0m\n",
       "\u001b[0;34m        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\u001b[0m\n",
       "\u001b[0;34m        [{1:1}, {2:5}, {3:1}, {4:1}].\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The \"balanced\" mode uses the values of y to automatically adjust\u001b[0m\n",
       "\u001b[0;34m        weights inversely proportional to class frequencies in the input data\u001b[0m\n",
       "\u001b[0;34m        as ``n_samples / (n_classes * np.bincount(y))``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The \"balanced_subsample\" mode is the same as \"balanced\" except that\u001b[0m\n",
       "\u001b[0;34m        weights are computed based on the bootstrap sample for every tree\u001b[0m\n",
       "\u001b[0;34m        grown.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        For multi-output, the weights of each column of y will be multiplied.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Note that these weights will be multiplied with sample_weight (passed\u001b[0m\n",
       "\u001b[0;34m        through the fit method) if sample_weight is specified.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    ccp_alpha : non-negative float, default=0.0\u001b[0m\n",
       "\u001b[0;34m        Complexity parameter used for Minimal Cost-Complexity Pruning. The\u001b[0m\n",
       "\u001b[0;34m        subtree with the largest cost complexity that is smaller than\u001b[0m\n",
       "\u001b[0;34m        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\u001b[0m\n",
       "\u001b[0;34m        :ref:`minimal_cost_complexity_pruning` for details.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.22\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    max_samples : int or float, default=None\u001b[0m\n",
       "\u001b[0;34m        If bootstrap is True, the number of samples to draw from X\u001b[0m\n",
       "\u001b[0;34m        to train each base estimator.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        - If None (default), then draw `X.shape[0]` samples.\u001b[0m\n",
       "\u001b[0;34m        - If int, then draw `max_samples` samples.\u001b[0m\n",
       "\u001b[0;34m        - If float, then draw `max_samples * X.shape[0]` samples. Thus,\u001b[0m\n",
       "\u001b[0;34m          `max_samples` should be in the interval `(0.0, 1.0]`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.22\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\u001b[0m\n",
       "\u001b[0;34m        The child estimator template used to create the collection of fitted\u001b[0m\n",
       "\u001b[0;34m        sub-estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 1.2\u001b[0m\n",
       "\u001b[0;34m           `base_estimator_` was renamed to `estimator_`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    base_estimator_ : DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m        The child estimator template used to create the collection of fitted\u001b[0m\n",
       "\u001b[0;34m        sub-estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. deprecated:: 1.2\u001b[0m\n",
       "\u001b[0;34m            `base_estimator_` is deprecated and will be removed in 1.4.\u001b[0m\n",
       "\u001b[0;34m            Use `estimator_` instead.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    estimators_ : list of DecisionTreeClassifier\u001b[0m\n",
       "\u001b[0;34m        The collection of fitted sub-estimators.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    classes_ : ndarray of shape (n_classes,) or a list of such arrays\u001b[0m\n",
       "\u001b[0;34m        The classes labels (single output problem), or a list of arrays of\u001b[0m\n",
       "\u001b[0;34m        class labels (multi-output problem).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_classes_ : int or list\u001b[0m\n",
       "\u001b[0;34m        The number of classes (single output problem), or a list containing the\u001b[0m\n",
       "\u001b[0;34m        number of classes for each output (multi-output problem).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_features_in_ : int\u001b[0m\n",
       "\u001b[0;34m        Number of features seen during :term:`fit`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.24\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    feature_names_in_ : ndarray of shape (`n_features_in_`,)\u001b[0m\n",
       "\u001b[0;34m        Names of features seen during :term:`fit`. Defined only when `X`\u001b[0m\n",
       "\u001b[0;34m        has feature names that are all strings.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 1.0\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_outputs_ : int\u001b[0m\n",
       "\u001b[0;34m        The number of outputs when ``fit`` is performed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    feature_importances_ : ndarray of shape (n_features,)\u001b[0m\n",
       "\u001b[0;34m        The impurity-based feature importances.\u001b[0m\n",
       "\u001b[0;34m        The higher, the more important the feature.\u001b[0m\n",
       "\u001b[0;34m        The importance of a feature is computed as the (normalized)\u001b[0m\n",
       "\u001b[0;34m        total reduction of the criterion brought by that feature.  It is also\u001b[0m\n",
       "\u001b[0;34m        known as the Gini importance.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Warning: impurity-based feature importances can be misleading for\u001b[0m\n",
       "\u001b[0;34m        high cardinality features (many unique values). See\u001b[0m\n",
       "\u001b[0;34m        :func:`sklearn.inspection.permutation_importance` as an alternative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    oob_score_ : float\u001b[0m\n",
       "\u001b[0;34m        Score of the training dataset obtained using an out-of-bag estimate.\u001b[0m\n",
       "\u001b[0;34m        This attribute exists only when ``oob_score`` is True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    oob_decision_function_ : ndarray of shape (n_samples, n_classes) or \\\u001b[0m\n",
       "\u001b[0;34m            (n_samples, n_classes, n_outputs)\u001b[0m\n",
       "\u001b[0;34m        Decision function computed with out-of-bag estimate on the training\u001b[0m\n",
       "\u001b[0;34m        set. If n_estimators is small it might be possible that a data point\u001b[0m\n",
       "\u001b[0;34m        was never left out during the bootstrap. In this case,\u001b[0m\n",
       "\u001b[0;34m        `oob_decision_function_` might contain NaN. This attribute exists\u001b[0m\n",
       "\u001b[0;34m        only when ``oob_score`` is True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See Also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\u001b[0m\n",
       "\u001b[0;34m    sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\u001b[0m\n",
       "\u001b[0;34m        tree classifiers.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    The default values for the parameters controlling the size of the trees\u001b[0m\n",
       "\u001b[0;34m    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\u001b[0m\n",
       "\u001b[0;34m    unpruned trees which can potentially be very large on some data sets. To\u001b[0m\n",
       "\u001b[0;34m    reduce memory consumption, the complexity and size of the trees should be\u001b[0m\n",
       "\u001b[0;34m    controlled by setting those parameter values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The features are always randomly permuted at each split. Therefore,\u001b[0m\n",
       "\u001b[0;34m    the best found split may vary, even with the same training data,\u001b[0m\n",
       "\u001b[0;34m    ``max_features=n_features`` and ``bootstrap=False``, if the improvement\u001b[0m\n",
       "\u001b[0;34m    of the criterion is identical for several splits enumerated during the\u001b[0m\n",
       "\u001b[0;34m    search of the best split. To obtain a deterministic behaviour during\u001b[0m\n",
       "\u001b[0;34m    fitting, ``random_state`` has to be fixed.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    References\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.ensemble import RandomForestClassifier\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.datasets import make_classification\u001b[0m\n",
       "\u001b[0;34m    >>> X, y = make_classification(n_samples=1000, n_features=4,\u001b[0m\n",
       "\u001b[0;34m    ...                            n_informative=2, n_redundant=0,\u001b[0m\n",
       "\u001b[0;34m    ...                            random_state=0, shuffle=False)\u001b[0m\n",
       "\u001b[0;34m    >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\u001b[0m\n",
       "\u001b[0;34m    >>> clf.fit(X, y)\u001b[0m\n",
       "\u001b[0;34m    RandomForestClassifier(...)\u001b[0m\n",
       "\u001b[0;34m    >>> print(clf.predict([[0, 0, 0, 0]]))\u001b[0m\n",
       "\u001b[0;34m    [1]\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mForestClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"class_weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mStrOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"balanced_subsample\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"splitter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sqrt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mestimator_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"criterion\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"max_depth\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_samples_split\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_samples_leaf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_weight_fraction_leaf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"max_leaf_nodes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"min_impurity_decrease\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"random_state\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"ccp_alpha\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moob_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mccp_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mccp_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda/envs/nobleprog_training/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=10,\n",
    "                               max_samples=0.7,\n",
    "                               max_features=0.8,\n",
    "                               max_depth=4, \n",
    "                               min_samples_split=2,\n",
    "                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=4, max_features=0.8, max_samples=0.7,\n",
       "                       n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, max_features=0.8, max_samples=0.7,\n",
       "                       n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=4, max_features=0.8, max_samples=0.7,\n",
       "                       n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on the test dataset is: 0.8571428571428571, 0.7058823529411765, 0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(f\"performance on the test dataset is: {precision}, {recall}, {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on the training dataset is: 0.8779342723004695, 0.6875, 0.7711340206185566\n"
     ]
    }
   ],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average='binary')\n",
    "print(f\"performance on the training dataset is: {precision_train}, {recall_train}, {f1_train}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz: can you try using grid search to find the best n_estimator, max_samples, and max_features?\n",
    "\n",
    "Hint: refer to the previous nb to find how to do grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 7, 'max_features': 0.6, 'max_samples': 0.9, 'min_samples_split': 3, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [5, 10, 15], 'max_features': [0.6, 0.8],\n",
    "              'max_samples': [0.7, 0.9], 'max_depth': [3, 5, 7], 'min_samples_split':[1, 2,3]}\n",
    "\n",
    "model = RandomForestClassifier(random_state=125)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='f1')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=7, max_features=0.6, max_samples=0.9,\n",
       "                       min_samples_split=3, n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=7, max_features=0.6, max_samples=0.9,\n",
       "                       min_samples_split=3, n_estimators=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=7, max_features=0.6, max_samples=0.9,\n",
       "                       min_samples_split=3, n_estimators=10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance on the test dataset is: 0.8888888888888888, 0.7058823529411765, 0.7868852459016393\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_valid, y_pred, average='binary')\n",
    "print(f\"performance on the test dataset is: {precision}, {recall}, {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance in random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13378032, 0.17724031, 0.05522459, 0.03872148, 0.2177356 ,\n",
       "       0.34609955, 0.01291118, 0.00714953, 0.01113743])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        property\n",
       "\u001b[0;31mString form:\u001b[0m <property object at 0x7fdfdbe70180>\n",
       "\u001b[0;31mSource:\u001b[0m     \n",
       "\u001b[0;31m# model.feature_importances_.fget\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mfeature_importances_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    The impurity-based feature importances.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The higher, the more important the feature.\u001b[0m\n",
       "\u001b[0;34m    The importance of a feature is computed as the (normalized)\u001b[0m\n",
       "\u001b[0;34m    total reduction of the criterion brought by that feature.  It is also\u001b[0m\n",
       "\u001b[0;34m    known as the Gini importance.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Warning: impurity-based feature importances can be misleading for\u001b[0m\n",
       "\u001b[0;34m    high cardinality features (many unique values). See\u001b[0m\n",
       "\u001b[0;34m    :func:`sklearn.inspection.permutation_importance` as an alternative.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    feature_importances_ : ndarray of shape (n_features,)\u001b[0m\n",
       "\u001b[0;34m        The values of this array sum to 1, unless all trees are single node\u001b[0m\n",
       "\u001b[0;34m        trees consisting of only the root node, in which case it will be an\u001b[0m\n",
       "\u001b[0;34m        array of zeros.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mall_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"threads\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature_importances_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_importances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mall_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_importances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mall_importances\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_importances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(711, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex_numeric    0.346100\n",
       "Fare           0.217736\n",
       "Age            0.177240\n",
       "Pclass         0.133780\n",
       "SibSp          0.055225\n",
       "Parch          0.038721\n",
       "Embarked_C     0.012911\n",
       "Embarked_S     0.011137\n",
       "Embarked_Q     0.007150\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=feature_imp, y=feature_imp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nobleprog_training",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
